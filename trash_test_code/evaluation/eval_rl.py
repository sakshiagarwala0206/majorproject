import os
import sys
import gymnasium
import numpy as np
import pickle
import time
import matplotlib.pyplot as plt
from gymnasium.envs.registration import register

# ğŸ”§ Add project root to import custom env
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))

# âœ… Import and register your custom environment
from environments.cartpole_rl import CartPoleEnv

register(
    id='CartPole-v1',
    entry_point='environments.cartpole_rl:CartPoleEnv',
)

# âœ… Load Q-table
with open("q_table_final.pkl", "rb") as f:
    q_table = pickle.load(f)

# ğŸ® Create the environment
env = gymnasium.make("CartPole-v1", render_mode="human")  # use "rgb_array" for headless
obs_low = env.observation_space.low
obs_high = env.observation_space.high

# âš™ï¸ Define bins (should match training)
bins = 10  # or load from saved config
def create_bins(low, high, bins):
    return [np.linspace(l, h, bins - 1) for l, h in zip(low, high)]

def discretize(obs, bins):
    return tuple(int(np.digitize(x, b)) for x, b in zip(obs, bins))

obs_bins = create_bins(obs_low, obs_high, bins)

# ğŸ“ˆ Evaluation loop
n_eval_episodes = 10
rewards = []

print("ğŸ¯ Starting Q-Learning Evaluation...")

for ep in range(n_eval_episodes):
    obs, _ = env.reset()
    state = discretize(obs, obs_bins)
    total_reward = 0
    done = False

    while not done:
        action = np.argmax(q_table[state])
        obs, reward, terminated, truncated, _ = env.step(action)
        state = discretize(obs, obs_bins)
        total_reward += reward
        done = terminated or truncated

        # Delay for visualization
        time.sleep(0.01)

    rewards.append(total_reward)
    print(f"âœ… Episode {ep + 1}: Total Reward = {total_reward}")

env.close()

# ğŸ“Š Evaluation summary
mean_reward = np.mean(rewards)
max_reward = np.max(rewards)
min_reward = np.min(rewards)

print("\nğŸ“Š Q-Learning Evaluation Summary:")
print(f"Average Reward: {mean_reward:.2f}")
print(f"Max Reward: {max_reward}")
print(f"Min Reward: {min_reward}")

# ğŸ“‰ Plot reward trend
plt.plot(range(n_eval_episodes), rewards, marker='o', label="Total Reward")
plt.title("Q-Learning Evaluation Rewards per Episode")
plt.xlabel("Episode")
plt.ylabel("Total Reward")
plt.grid(True)
plt.tight_layout()
plt.legend()
plt.show()
