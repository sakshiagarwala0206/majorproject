
# ğŸ§  DDPG Inference on Custom Inverted Pendulum (PyBullet + Gymnasium)

This project demonstrates real-time **inference** using a pre-trained **DDPG (Deep Deterministic Policy Gradient)** model on a **custom inverted pendulum environment** built using **PyBullet** and **Gymnasium**.

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ cartpole_env.py                 # Custom environment (PyBullet + Gymnasium API)
â”œâ”€â”€ inference_ddpg_pendulum.py     # Inference script with action noise
â”œâ”€â”€ ddpg_inverted_pendulum.zip     # Trained DDPG model (loaded via SB3)
â”œâ”€â”€ pendulum.urdf                  # URDF file describing the robot
â”œâ”€â”€ README.md                      # This file
```

---

## âš™ï¸ Environment Overview

Your environment simulates an **inverted pendulum system** with:

- **Slider joint** for cart movement (prismatic joint).
- **Hinge joint** for the pole (revolute joint).
- Uses **PyBullet** for physics simulation.
- Complies with **Gymnasium**'s API (`reset`, `step`, `render`, etc.).

> Ensure your `InvertedPendulumEnvGymnasium` class is correctly registered or imported in `cartpole_env.py`.

---

## ğŸ§ª Inference Script Breakdown

File: `inference_ddpg_pendulum.py`

### ğŸ”¹ Key Features

- Loads a pre-trained DDPG model from Stable Baselines3.
- Adds **Gaussian noise** to actions during inference to encourage slight exploration.
- Uses `env.step()` to interact with the custom environment.
- Tracks **pole angle** to detect "balanced" states.
- Stops an episode early if the pole stays balanced for 50 steps.

### ğŸ”¸ Action Noise

```python
from stable_baselines3.common.noise import NormalActionNoise
action_noise = NormalActionNoise(mean=np.zeros(env.action_space.shape),
                                  sigma=0.05 * np.ones(env.action_space.shape))
```

This simulates small deviations from deterministic policy actions for robustness.

---

## â–¶ï¸ Running Inference

Make sure all dependencies are installed:

```bash
pip install stable-baselines3 gymnasium[all] pybullet numpy
```

Then run:

```bash
python inference_ddpg_pendulum.py
```

### Expected Behavior

- A window opens showing the pendulum balancing in real time.
- The script prints rewards, actions, and pole angle.
- If the pole stays within Â±0.05 radians for 50 consecutive steps, the episode ends early.

---

## ğŸ“Š Observations and Debugging

- `obs[2]` is assumed to be the **pole angle**.
- Adjust noise levels or pole angle thresholds as needed.
- For persistent debugging/logging, consider logging:
  - Actions
  - Rewards
  - Pole angle
  - Episode length

---

## ğŸ§  DDPG Notes

- Suitable for continuous action spaces like motor torques.
- Works well with low-dimensional state vectors like inverted pendulum angles and velocities.

---

## ğŸš€ Next Steps

- ğŸ¥ Add video recording using `gymnasium.wrappers.RecordVideo`
- ğŸ“‰ Plot reward curve over episodes
- ğŸ› ï¸ Test different levels of noise
- ğŸ“¦ Run inference on a Raspberry Pi or embedded device
- ğŸ§ª Compare with PPO or SAC

---

Made with â¤ï¸ for balancing robots.

```

